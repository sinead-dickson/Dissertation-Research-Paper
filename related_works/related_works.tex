\section{Related Works}

\subsection{Classification}

Classification, in the context of machine learning, is the process of mapping observations into classes, based on some set of training data. There are two main approaches to classification, supervised and unsupervised learning. A supervised machine learning approach will be taken in this research. A collection of tweets will be manually annotated and assigned one of the following three labels: Review, Some Content, or Irrelevant. These annotated tweets will be used to train a text classifier. 

Twitter data has a different format to standard long-form text and needs to be treated differently. Tweets are short with a maximum of 280 characters. This has led to the use of particular characteristic features. Tweets are generally very informal, using casual language and slang. They contain features like hashtags, emojis, Twitter handles, URLs, images, videos and gifs, which don't occur in standard text. The short length and non-standard features can create a challenge for standard text classification algorithms and standard machine learning document representations. A number of papers have investigated the performance of different classification algorithms and feature representations on Twitter data. 

\cite{Berm2010} investigated the performance of Support Vector Machines (SVM) and Multinomial Na√Øve Bayes (MNB) in classifying the sentiment of short versus long form text documents. Maximum accuracy of 74.85\% was achieved with MNB versus 73.45\% with SVM, for the Twitter data. Overall MNB achieves better accuracy than SVM on the short form documents, from both Twitter and Blippr (a micro-review site). \cite{Berm2010} also found that extending the unigram feature representation improved classification accuracy for the long form documents, but not for the short form documents. Part-of-Speech features and punctuation aided classification of the short form documents.

An Ensemble Classifier was proposed by \cite{Ankit2018} to classify the sentiment of tweets. The proposed weighted ensemble classifier outperforms each of the individual base classifiers, as well as the majority voting ensemble classifier. \cite{Kanakaraj2015} also found that ensemble methods performed better in classifying the sentiment of tweets than base classifiers. They compared several base classifiers and ensemble methods, and found the ensemble methods again outperformed the individual base classifiers, with Extremely Randomised Trees performing the best.

\cite{sriram2010} classified tweets into a set of generic classes: News, Opinions, Events, Deals and Private Messages. They proposed an eight-feature technique. Eight features were extracted from the tweets, one nominal (author) and seven binary (whether the tweet contained shortened words/slang, time-event phrases, opinion words, emphasis on words, currency or percentage signs, whether the tweet username is at the start, and whether the username is mid-tweet). They compared their 8-feature technique to bag-of-words (BOW) and found it performed significantly better.

\cite{Raithi2018} tested SVM, AdaBoosted Decision Tree (ADT) and Decision Tree (DT) Classifiers, for classifying the sentiment of tweets. Term Frequency - Inverse Document Frequency (TF-IDF) Vectorization is applied during pre-processing. The weights from TF-IDF are applied to the dataset emphasising the contribution of some words and reducing the contribution of others. They found the DT (84\%) achieved the highest accuracy followed by the SVM (82\%) and then the ADT (67\%).

\cite{Rane2018} compared the performance of classification algorithms in classifying the sentiment of Twitter reviews about US Airline Services. Doc2Vec feature representation was used, which involves mapping each document to a vector in space. In this study, each paragraph was mapped to a vector. The Random Forest Classifier performed the best, with reported precision of 85.6\%, recall of 86.5\% and accuracy of 86.5\%. 

\subsection{Sentiment Analysis}

Sentiment analysis is the process of identifying the opinion expressed about a particular subject in some text. The aim is to determine whether the opinion is positive, negative or neutral, and to what extent. There are two main approaches to sentiment analysis, lexicon based approaches and supervised machine learning based approaches. A lexicon-based approach works by classifying a sentence based on the number of opinion words (positive or negative words) in the sentence. A sentiment score is calculated based on the ratio of positive to negative words. Supervised machine learning approaches require labelled training data. Their performance is very dependent on the size and quality of the set of training data. 

\cite{Bhuta2014} reviewed different methods for the sentiment analysis of text, with a focus on Twitter. These included a lexicon approach and three supervised learning methods, Naive Bayes, Maximum Entropy and Support Vector Machines. The three supervised learning methods generally outperformed the lexicon-based approach. A disadvantage of the supervised machine learning methods is that they can be a 'black box' method. It can be hard to know exactly what is having an effect on the algorithm and how to improve it.

The Stanford NLP Group's Sentiment Analyser \cite{stanfordSentiment2013} introduced a Recursive Neural Tensor Network (RNTN) along with a Sentiment Treebank. The Sentiment Treebank extended the corpus of movie reviews originally collected by Pang and Lee \cite{panglee2004}. The sentences in the movie review corpus were relabelled at a phrase level, producing a sentiment labelled parse-tree for each review. The Sentiment Treebank produced has more finely grained sentiment labels than the original corpus. It improved how the compositional effects of sentiment in language were captured. All classification models trained with the Sentiment Treebank saw a significant increase in accuracy. These included Naive Bayes, Support Vector Machines, and other recursive neural networks. The RNTN achieved the highest accuracy of 85.4\% in single sentence positive/negative classification.

\subsection{Recommender Systems}

Recommender systems provide suggestions for items that are most likely to be of interest to a particular user \cite{Ricci2015}. They recommend based on user behaviours and preferences, such as explicit user ratings and reviews of products, and implicit user clicks and view times. There are two main methods that recommender systems use to generate recommendations, Collaborative Filtering methods and Content-Based recommender methods. Collaborative Filtering methods analyse the behaviour of a collection of users and use this information to make recommendations based upon what users similar to the current user have liked. The basic idea is that if we know two users have the same opinion on one item, then they are more likely to have the same opinion on another item. The correlation between users is used to make predictions. Content-Based (CB) recommender methods use the descriptive features of items and the preferences of individual users. Information about each user and the content information about each item is combined to make recommendations. CB methods recommend items similar to items the user liked or purchased in the past.

Another piece of information used by recommender systems is context. Context-aware recommender systems use contextual information to improve their recommendations. This contextual information could be time, location, company etc. The concept is that the same user could prefer different items under different conditions.

A number of recommender systems that focus on hotels have been proposed in the literature. \cite{levi2012} proposed a cold start, context-based hotel recommender system, which uses the text of online reviews from Tripadvisor and Venere as its main data. The system asks the user to identify their trip intent (business, family, etc), nationality and preferences for certain hotel features (location, service, food, etc). Hotels are recommended based on the sentiment of reviews of users who have similar context information. The sentiment score is calculated with a lexicon based approach. They reported that users were 20\% more satisfied with their recommendations. This is a promising result for this research. The hope is that incorporating review-like tweets into the CoRE recommender will also increase user satisfaction. 

Another recommender system that targets hotels was proposed by \cite{lin2015}. It also uses hotel reviews collected from TripAdvisor. The system tracks the user's gestures on a mobile device to identify what part of the review the user has focused on or 'seriously read'. Feature extraction is used to extract the aspects of hotels (e.g room, food, price etc) the user considers important, and build a user interest profile. Hotels are recommended based on the user profile. The score is calculated based on the sentiment of the reviews about the aspects of the hotels the user prefers.

\cite{chang2018} proposed a hotel recommendation system that uses a combination of Twitter and Yelp data. They use a collaborative filtering method. The idea is that Twitter provides limited information on its own, but when combined with Yelp, which has explicit user ratings, can achieve better performance in a recommender system. User posting behaviour vectors are generated for both Twitter and Yelp and are combined to make recommendations.

\cite{takeharaContext2012} propose a rule-based method of extracting context information from Twitter for use alongside a restaurant recommender system. Relevant keywords are extracted from reviews from Tabelog (a Japanese review site) and are used to search Twitter for the contextual information. Restaurant and area related nouns are extracted from Tabelog using part-of-speech tagging. Tweets containing more than two nouns from each set of keywords (area and restaurant) are selected as the contextual information and are displayed alongside the restaurant recommendations.