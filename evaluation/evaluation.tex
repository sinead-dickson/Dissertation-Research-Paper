\section{Evaluation}

\subsection{Evaluation Metrics for Classification}

\subsubsection{Precision}
Precision is the percentage of positive identifications that were classified correctly.\newline
\begin{equation}
    Precision\ =\ \frac{True\ Positives}{True\ Positives\ +\ False\ Positives}
\end{equation}

\subsubsection{Recall}
Recall is the percentage of all actual positives that were classified correctly.
\begin{equation}
    Recall\ =\ \frac{True\ Positives}{True\ Positives\ +\ False\ Negatives}
\end{equation}

\subsubsection{F1-Score}
F1-Score is the harmonic mean of precision and recall. It is also called the F-Score or F-Measure. 
\begin{equation}
    F1-Score\ =\ 2 \times\ \frac{Precision\ \times\ Recall}{Precision\ +\ Recall}
\end{equation}

\subsubsection{Accuracy}
Accuracy is the total number of predictions the classifier got right. It is the percentage of the tweets that were classified correctly.
\begin{equation}
    Accuracy\ =\ \frac{Number\ of\ Correct\ Predictions}{Total\ Number\ of\ Predictions}
\end{equation}

\subsection{Classification Results and Analysis}

\subsubsection{Classifiers}

\begin{table}[h!]
\caption{Precision of Classifiers for different Feature Representations.}
\label{Table:precision}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccccc}
\specialrule{1.5pt}{1pt}{1pt}
 & \textbf{BOW} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Bigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Trigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram,\\ No Stop Words)\end{tabular}} & \textbf{Word2Vec} & \textbf{Doc2Vec} \\ \specialrule{1.5pt}{1pt}{1pt}
\textbf{RF} & 0.72 & 0.74 & 0.7 & 0.69 & 0.73 & 0.71 & 0.59  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{DT} & 0.57 & 0.58 & 0.58 & 0.59 & 0.63 & 0.54 & 0.56  \\ \hline
\textbf{MLP} & 0.71 & 0.71 & 0.7 & 0.7 & 0.7 & 0.71 & 0.59  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{SVM} & 0.56 & 0.74 & 0.73 & 0.71 & 0.71 & 0.71 & 0.62  \\ \hline
\textbf{LR} & 0.72 & 0.72 & 0.7 & 0.68 & 0.7 & 0.71 & 0.61  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{KNN} & 0.53 & 0.62 & 0.62 & 0.62 & 0.61 & 0.67 & 0.54  \\ \hline
\textbf{GP} & 0.72 & 0.72 & 0.71 & 0.69 & 0.7 & 0.72 & 0.61  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{AB} & 0.63 & 0.62 & 0.63 & 0.62 & 0.64 & 0.63 & 0.57  \\ \hline
\textbf{GNB} & 0.6 & 0.6 & 0.63 & 0.63 & 0.59 & 0.64 & 0.59  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{MNB} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}0.71} & 0.67 & 0.68 & 0.66 & 0.67 & 0.32 & 0.35    \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{BNB} & 0.73 & 0.73 & 0.71 & 0.71 & 0.72 & 0.65 & 0.58  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{QDA} & 0.72 & 0.76 & 0.73 & 0.67 & \textcolor{red}{0.79} & 0.59 & 0.57  \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{LDA} & 0.63 & 0.64 & 0.65 & 0.63 & 0.62 & 0.69 & 0.66  \\ \hline
\end{tabular}}
\end{table}

\begin{table}[h!]
\caption{Recall of Classifiers for different Feature Representations.}
\label{Table:recall}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccccc}
\specialrule{1.5pt}{1pt}{1pt}
 & \textbf{BOW} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Bigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Trigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram,\\ No Stop Words)\end{tabular}} & \textbf{Word2Vec} & \textbf{Doc2Vec} \\ \specialrule{1.5pt}{1pt}{1pt}
\textbf{RF} & 0.7 & 0.71 & 0.7 & 0.69 & 0.72 & 0.69 & 0.64  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{DT} & 0.61 & 0.6 & 0.61 & 0.62 & 0.65 & 0.56 & 0.59  \\ \hline
\textbf{MLP} & 0.72 & 0.72 & 0.71 & 0.71 & 0.71 & 0.72 & 0.62  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{SVM} & 0.59 & \textcolor{red}{0.74} & \textcolor{red}{0.74} & 0.72 & 0.72 & 0.72 & 0.64  \\ \hline
\textbf{LR} & 0.72 & 0.72 & 0.71 & 0.7 & 0.71 & 0.72 & 0.64  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{KNN} & 0.61 & 0.66 & 0.66 & 0.65 & 0.65 & 0.68 & 0.61  \\ \hline
\textbf{GP} & 0.73 & 0.73 & 0.72 & 0.71 & 0.71 & 0.73 & 0.64  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{AB} & 0.65 & 0.64 & 0.65 & 0.65 & 0.66 & 0.64 & 0.61  \\ \hline
\textbf{GNB} & 0.48 & 0.48 & 0.47 & 0.45 & 0.48 & 0.56 & 0.49  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{MNB} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}0.66} & 0.68 & 0.69 & 0.67 & 0.68 & 0.57 & 0.59  \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{BNB} & 0.71 & 0.71 & 0.66 & 0.62 & 0.71 & 0.56 & 0.54  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{QDA} & 0.26 & 0.23 & 0.24 & 0.56 & 0.26 & 0.61 & 0.68  \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{LDA} & 0.61 & 0.61 & 0.61 & 0.59 & 0.59 & 0.69 & 0.67  \\ \hline
\end{tabular}}
\end{table}

\begin{table}[h!]
\caption{F1-Score of Classifiers for different Feature Representations.}
\label{Table:f1score}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccccc}
\specialrule{1.5pt}{1pt}{1pt}
 & \textbf{BOW} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Bigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Trigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram,\\ No Stop Words)\end{tabular}} & \textbf{Word2Vec} & \textbf{Doc2Vec} \\ \specialrule{1.5pt}{1pt}{1pt}
\textbf{RF} & 0.65 & 0.65 & 0.64 & 0.64 & 0.69 & 0.63 & 0.59  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{DT} & 0.57 & 0.59 & 0.58 & 0.6 & 0.63 & 0.54 & 0.56  \\ \hline
\textbf{MLP} & 0.71 & 0.7 & 0.69 & 0.69 & 0.69 & 0.71 & 0.57  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{SVM} & 0.45 & \textcolor{red}{0.73} & \textcolor{red}{0.73} & 0.71 & 0.71 & 0.71 & 0.63  \\ \hline
\textbf{LR} & 0.71 & 0.7 & 0.69 & 0.68 & 0.69 & 0.71 & 0.6  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{KNN} & 0.49 & 0.62 & 0.62 & 0.62 & 0.61 & 0.67 & 0.55  \\ \hline
\textbf{GP} & 0.71 & 0.71 & 0.72 & 0.7 & 0.7 & 0.72 & 0.61  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{AB} & 0.63 & 0.62 & 0.63 & 0.62 & 0.63 & 0.63 & 0.59  \\ \hline
\textbf{GNB} & 0.5 & 0.51 & 0.49 & 0.47 & 0.5 & 0.58 & 0.51  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{MNB} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}0.67} & 0.63 & 0.66 & 0.65 & 0.64 & 0.41 & 0.44 \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{BNB} & 0.72 & 0.72 & 0.67 & 0.64 & 0.71 & 0.58 & 0.55  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{QDA} & 0.23 & 0.19 & 0.19 & 0.48 & 0.23 & 0.55 & 0.61  \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{LDA} & 0.62 & 0.62 & 0.62 & 0.6 & 0.6 & 0.69 & 0.66  \\ \hline
\end{tabular}}
\end{table}

\begin{table}[h!]
\caption{Accuracy of Classifiers for different Feature Representations.}
\label{Table:accuracy}
\resizebox{\columnwidth}{!}{
\begin{tabular}{cccccccc}
\specialrule{1.5pt}{1pt}{1pt}
 & \textbf{BOW} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Bigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Trigram)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ (Unigram,\\ No Stop Words)\end{tabular}} & \textbf{Word2Vec} & \textbf{Doc2Vec} \\ \specialrule{1.5pt}{1pt}{1pt}
\textbf{RF} & 0.703 & 0.706 & 0.696 & 0.691 & 0.721 & 0.677 & 0.635  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{DT} & 0.614 & 0.596 & 0.614 & 0.621 & 0.652 & 0.563 & 0.594  \\ \hline
\textbf{MLP} & 0.719 & 0.719 & 0.711 & 0.711 & 0.709 & 0.718 & 0.621  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{SVM} & 0.594 & \textcolor{red}{0.744} & 0.737 & 0.718 & 0.724 & 0.716 & 0.637  \\ \hline
\textbf{LR} & 0.724 & 0.721 & 0.709 & 0.696 & 0.713 & 0.722 & 0.639  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{KNN} & 0.608 & 0.655 & 0.657 & 0.652 & 0.649 & 0.681 & 0.609  \\ \hline
\textbf{GP} & 0.726 & 0.726 & 0.724 & 0.706 & 0.708 & 0.729 & 0.644  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{AB} & 0.654 & 0.644 & 0.650 & 0.650 & 0.655 & 0.637 & 0.609  \\ \hline
\textbf{GNB} & 0.478 & 0.483 & 0.473 & 0.448 & 0.479 & 0.565 & 0.486  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{MNB} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}0.660} & 0.683 & 0.691 & 0.675 & 0.678 & 0.569 & 0.588  \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{BNB} & 0.713 & 0.713 & 0.662 & 0.621 & 0.709 & 0.565 & 0.537  \\ \hline
\rowcolor[HTML]{EFEFEF} 
\textbf{QDA} & 0.263 & 0.235 & 0.238 & 0.558 & 0.261 & 0.612 & 0.678  \\ \hline
\rowcolor[HTML]{FFFFFF} 
\textbf{LDA} & 0.609 & 0.614 & 0.609 & 0.588 & 0.591 & 0.693 & 0.665  \\ \hline
\end{tabular}}
\end{table}

\subsection{Evaluation Metrics for Recommender Systems}
\subsubsection{Leave-One-Out}
The 'leave-one-out' cross validation approach involves removing one of a users n hotel bookings and using their remaining hotel bookings to generate the hotel recommendations. A list of hotels ranked in descending order by their predicted value is produced. The booking that was removed is compared to this list to see where it ranked, the higher the better. This is repeated with each of the users n bookings.

The 'leave-one-out' approach was used because of the data that we have. We do not have any explicit user reactions to hotel recommendations but we do have implicit feedback in the form of user hotel bookings.

\subsubsection{Mean Percentile Rank}
The Mean Percentile Rank (MPR) is calculated based on the rankings recorded through leave-one-out cross validation. MPR is a recall-based measure. It measures the user satisfaction of items in an ordered list. The MPR formula is as follows:

\begin{equation}
    MPR = \frac{ \sum_{u,i} r_{ui} \times rank_{ui} } {\sum_{u,i} r_{ui}}
\end{equation}

$rank_{ui}$ is the percentile-ranking of hotel i within the ordered list of all hotels ranked for user u. $r_{ui}$ is a binary variable indicating whether user u booked hotel i. $rank_{ui} = 100\%$ indicates that the hotel i is predicted to be less desirable for user u. $rank_{ui} = 0\%$ indicates that the hotel i is predicted to be the most desirable hotel for user u. $rank_{ui} = 50\%$ would be expected for a list of randomly ranked hotels.

\subsection{Recommender Results and Analysis}


\begin{table}[h!]
\caption{Recommender Systems Performance.}
\label{Table:senticore}
\resizebox{\columnwidth}{!}{
\begin{tabular}{ll}
\specialrule{1.5pt}{1pt}{1pt}
\textbf{Recommender System} & \textbf{MPR (\%)} \\ \specialrule{1.5pt}{1pt}{1pt}
\rowcolor[HTML]{EFEFEF}
Random & 42.72 \\ \hline
Expedia Baseline & 40.87 \\ \hline
\rowcolor[HTML]{EFEFEF}
CoRE (with feature weighting) & 2.51 \\ \hline
CoRE (without feature weighting) & 3.31 \\ \hline
\rowcolor[HTML]{EFEFEF}
SentiCoRE (with feature weighting) & 14.68 \\ \hline
SentiCoRE (without feature weighting) & 9.92 \\ \hline
\end{tabular}}
\end{table}