\section{Conclusion}

In this paper, two problems were addressed. The first was to assess if it was possible to classify whether a tweet contains content which could be deemed to be a review. The second was to determine to what extent Twitter can provide a suitable source of online reviews that can be used effectively in the generation of recommendations in a recommender system.

We evaluated the performance of thirteen classifiers. The best performing classifier was the Support Vector Machine Classifier. It achieved a precision score of 74\%, a recall score of 74\%, an f1-score of 73\% and an accuracy score of 74.4\%. The best performing feature representation was unigram TF-IDF. These results confirm that text classification is a valid method of extracting reviews from Twitter. 

Sentiment analysis was performed on the tweets that were classified as reviews, using the Stanford NLP Sentiment Analyser. The sentiment scores produced were used to re-rank the results of the CoRE recommender system. Incorporating the sentiment scores into the CoRE recommender had the desired effect and adjusted the rankings of the hotels. But in terms of MPR SentiCoRE performed worse than CoRE.

Several promising lines of future work have been identified during the course of this research. One line of future work would be to improve the classification performance of the machine learning algorithms. This could be achieved by increasing the size of the training set or investigating other classification algorithms and feature representations. A possible improvement to the methodology outlined in this project would be re-training the Stanford NLP Sentiment Analyser on a dataset more similar to our set of tweets. Another important line of future work would be to evaluate the performance of the recommender system on a larger dataset. In this project, the system was evaluated for 27 users and 21 hotels. Our results could be confirmed and would hold more weight if the recommender was re-evaluated with data for more users and hotels.

